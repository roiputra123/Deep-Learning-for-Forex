{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Time Series Forecasting\n\nIn this example, we use a feature representation pipeline to forecast a continuous time series\ntarget with a regressor.\n\nThe algorithm is trained from the target from the features and targets in the training set.\nThen predict (future segments) from the features in the test set.\n\nWe do not sequentially retrain the algorithm as we move through the test set - which is an\napproach you will sometimes see with time series forecasting (and which may or may not be\nuseful in your application).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: David Burns\n# License: BSD\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nfrom seglearn.pipe import Pype\nfrom seglearn.split import temporal_split\nfrom seglearn.transform import FeatureRep, SegmentXYForecast, last\n\nt = np.arange(5000) / 100.\ny = np.sin(t) * t * 2.5 + t * t\n\n# with forecasting, X can include the target\nX = np.stack([t, y], axis=1)\n\n# remember for a single time series, we need to make a list\nX = [X]\ny = [y]\n\n# split the data along the time axis (our only option since we have only 1 time series)\nX_train, X_test, y_train, y_test = temporal_split(X, y, test_size=0.25)\n\n# create a feature representation pipeline\n# setting y_func = last, and forecast = 200 makes us predict the value of y\n# 200 samples ahead of the segment\n# other reasonable options for y_func are ``mean``, ``all`` (or create your own function)\n# see the API documentation for further details\nclf = Pype([('segment', SegmentXYForecast(width=200, overlap=0.5, y_func=last, forecast=200)),\n            ('features', FeatureRep()),\n            ('lin', LinearRegression())])\n\n# fit and score\nclf.fit(X_train, y_train)\nscore = clf.score(X_test, y_test)\n\nprint(\"N series in train: \", len(X_train))\nprint(\"N series in test: \", len(X_test))\nprint(\"N segments in train: \", clf.N_train)\nprint(\"N segments in test: \", clf.N_test)\nprint(\"Score: \", score)\n\n# generate some predictions\ny, y_p = clf.transform_predict(X, y)  # all predictions\nytr, ytr_p = clf.transform_predict(X_train, y_train)  # training predictions\nyte, yte_p = clf.transform_predict(X_test, y_test)  # test predictions\n\n# note - the first few segments in the test set won't have predictions (gap)\n# we plot the 'gap' for the visualization to hopefully make the situation clear\nNs = len(y)\nts = np.arange(Ns)  # segment number\nttr = ts[0:len(ytr)]\ntte = ts[(Ns - len(yte)):Ns]\ntga = ts[len(ytr):(Ns - len(yte))]\nyga = y[len(ytr):(Ns - len(yte))]\n\n# plot the results\nplt.plot(ttr, ytr, '.', label=\"training\")\nplt.plot(tga, yga, '.', label=\"gap\")\nplt.plot(tte, yte, '.', label=\"test\")\nplt.plot(tte, yte_p, label=\"predicted\")\n\nplt.xlabel(\"Segment Number\")\nplt.ylabel(\"Target\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}